{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\New-User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (329,331,333,336,338,344,345,346,348,354,355,356,357,358,361,362,364,367,372,377,380,383,385,387,390,392,399,400,406,408,409,413,416,418,419,431,433,437,438,442,448,449,450,453,457,464,473,478,479,481,483,485,486,489,492,495,496,497,498,499,500,503,507,508,510,511,514,515,517,519,520,521,522,523,524,526,527,530,534,537,538,539,541,544,547,548,549,550,551,557,558,560,564,569,572,573,576,577,579,583,596,597,598,600,601,602,604,605,606,608,609,613,619,620,625,627,628,629,631,632,633,636,641,642,643,645,646,647,648,651,655,661,662,665,668,675,676,679,682,685,687,689,690,691,694,698,701,702,703,706,711,712,713,719,720,721,733,735,737,738,742,746,747,748,749,752,754,755,760,764,768,770,781,782,789,797,807,812,814,817,818,822,823,824,825,832,840,843,844,845,850,853,857,858,861,867,868,873,874,876,877,879,880,881,883,886,890,893,897,899,900,901,902,904,905,908,909,910,912,913,914,915,916,922,923,931,933,935,937,939,942,943,946,951,955,960,964,965,968,969,970,973,974,977,980,987,994,995,996,999,1000,1008,1014,1015,1016,1017,1020,1021,1023,1028,1031,1035,1036,1037,1039,1040,1043,1048,1051,1055,1058,1059,1072,1073,1074,1081,1090,1097,1098,1103,1104,1109,1112,1113,1114,1118,1120,1130,1134,1135,1139,1140,1147,1148,1149,1152,1154,1157,1158,1162,1163,1164,1166,1169,1174,1177,1180,1181,1182,1183,1185,1188,1189,1195,1197,1198,1200,1203,1208,1210,1212,1215,1217,1220,1222,1225,1229,1230,1233,1234,1241,1243,1246,1250,1251,1252,1254,1259,1262,1263,1265,1266,1269,1270,1273,1274,1276,1277,1279,1280,1282,1284,1285,1286,1289,1291,1292,1293,1294,1295,1301,1302,1304,1305,1306,1308,1309,1311,1313,1316,1318,1320,1322,1323,1325,1330,1335,1337,1340,1341,1343,1345,1350,1351,1352,1354,1357,1358,1359,1360,1361,1368,1369,1372,1377) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"train Data.csv\")\n",
    "train_data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"train labels.csv\")\n",
    "train_labels.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(thresh=int(len(train_data)/ 2), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real values\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "# Categorical Values\n",
    "train_data.fillna(train_data.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0012</th>\n",
       "      <th>n_0019</th>\n",
       "      <th>n_0034</th>\n",
       "      <th>n_0038</th>\n",
       "      <th>n_0047</th>\n",
       "      <th>n_0050</th>\n",
       "      <th>n_0052</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1326</th>\n",
       "      <th>c_1328</th>\n",
       "      <th>c_1330</th>\n",
       "      <th>c_1333</th>\n",
       "      <th>c_1335</th>\n",
       "      <th>c_1343</th>\n",
       "      <th>c_1348</th>\n",
       "      <th>c_1361</th>\n",
       "      <th>c_1363</th>\n",
       "      <th>c_1372</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>a</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>a</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>q</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16531</th>\n",
       "      <td>a</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>u</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>a</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18262</th>\n",
       "      <td>c</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      release  n_0002  n_0005  n_0012  n_0019  n_0034  n_0038  n_0047  n_0050  \\\n",
       "id                                                                              \n",
       "11193       a    0.03    0.37    0.29     0.0    0.22    0.19       1       1   \n",
       "11382       a    0.03    0.32    0.24     0.0    0.10    0.18       1       1   \n",
       "16531       a    0.02    0.34    0.30     0.0    0.12    0.29       1       1   \n",
       "1896        a    0.04    0.45    0.21     0.0    0.15    0.37       1       1   \n",
       "18262       c    0.04    0.32    0.22     0.0    0.07    0.18       1       1   \n",
       "\n",
       "       n_0052  ...  c_1326  c_1328  c_1330  c_1333  c_1335  c_1343  c_1348  \\\n",
       "id             ...                                                           \n",
       "11193       1  ...       g       b       a       e       w       b       b   \n",
       "11382       1  ...       s       b       a       e       q       b       b   \n",
       "16531       1  ...       t       a       b       e       u       a       b   \n",
       "1896        1  ...       g       b       b       e       w       a       b   \n",
       "18262       1  ...       w       a       a       e       b       b       b   \n",
       "\n",
       "       c_1361  c_1363  c_1372  \n",
       "id                             \n",
       "11193       e       b       a  \n",
       "11382       e       b       a  \n",
       "16531       c       a       a  \n",
       "1896        g       a       a  \n",
       "18262       e       b       a  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]) \n",
    "gj = np.array([-3.9752, -3.4848, -2.9720, -4.7062, -4.1345, -3.9000, -4.2158, -4.1687, -4.5050,  4.8135,  4.0907, -4.6027, -4.5086, -5.3354])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "gj[gj < 0] = 0 \n",
    "gj[gj > 0] = 1\n",
    "print(gj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_csv(\"X_train_RE.csv\")\n",
    "# train_labels.to_csv(\"y_train_RE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Bunch(data=train_data, target=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.data.loc[997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test \\\n",
    "        = train_test_split(h.data, h.target, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val \\\n",
    "        = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Solving environment: ...working... \n",
      "Warning: 4 possible package resolutions (only showing differing packages):\n",
      "  - anaconda/win-64::ca-certificates-2020.10.14-0, anaconda/win-64::openssl-1.1.1h-he774522_0\n",
      "  - anaconda/win-64::ca-certificates-2020.10.14-0, defaults/win-64::openssl-1.1.1h-he774522_0\n",
      "  - anaconda/win-64::openssl-1.1.1h-he774522_0, defaults/win-64::ca-certificates-2020.10.14-0\n",
      "  - defaults/win-64::ca-certificates-2020.10.14-0, defaults/win-64::openssl-1.1.1h-he774522_0done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%conda install torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install -c anaconda opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def data2img(arr, font_size=50, resolution=(256, 256), font=cv2.FONT_HERSHEY_SIMPLEX):\n",
    "    \"\"\" Structured Tabular Data to Image with cv2\n",
    "\n",
    "        NOTE currently supports only iris and wine dataset\n",
    "    \"\"\"\n",
    "    x, y = resolution\n",
    "    n_colums, n_features = 2, len(arr)\n",
    "    n_lines = n_features % n_colums + int(n_features / n_colums)\n",
    "    frame = np.ones((*resolution, 3), np.uint8)*0\n",
    "\n",
    "    k = 0\n",
    "    dataset='mltoy'\n",
    "    # ----- iris -----\n",
    "    if dataset=='iris':\n",
    "        for i in range(n_colums):\n",
    "            for j in range(n_lines):\n",
    "                try:\n",
    "                    cv2.putText(\n",
    "                        frame, str(arr[k]), (30+i*(x//n_colums), 5+(j+1)*(y//(n_lines+1))),\n",
    "                        fontFace=font, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "                    k += 1\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "    # ----- wine -----\n",
    "    elif dataset=='wine':\n",
    "        for i in range(n_colums):\n",
    "            for j in range(n_lines):\n",
    "                try:\n",
    "                    cv2.putText(\n",
    "                        frame, str(arr[k]), (30+i*(x//n_colums), 5+(j+1)*(y//(n_lines+1))),\n",
    "                        fontFace=font, fontScale=0.6, color=(255, 255, 255), thickness=1)\n",
    "                    k += 1\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "    # ----- toy -----\n",
    "    elif dataset=='mltoy':\n",
    "        for i in range(n_colums):\n",
    "            for j in range(n_lines):\n",
    "                try:\n",
    "                    cv2.putText(\n",
    "                        frame, str(arr[k]), (10+i*(x//n_colums), 5+(j+1)*(y//(n_lines+1))),\n",
    "                        fontFace=font, fontScale=0.2, color=(255, 255, 255), thickness=1)\n",
    "                    k += 1\n",
    "                except IndexError:\n",
    "                    break\n",
    "\n",
    "\n",
    "    return np.array(frame, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         x = self.data[0][index]\n",
    "#         print(self.data[0],index)\n",
    "#         print(self.data[0].loc[0])\n",
    "        x = self.data[0].loc[index]\n",
    "            \n",
    "        img = data2img(x)\n",
    "        if self.transform:\n",
    "            x = self.transform(img)\n",
    "\n",
    "        y = self.data[1].loc[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "kwargs = {} if device=='cpu' else {'num_workers': 2, 'pin_memory': True}\n",
    "loader_kwargs = {'batch_size':4, **kwargs}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "# x_train.reset_index(inplace=True)\n",
    "# y_train.reset_index(inplace=True)\n",
    "# Build Dataset\n",
    "train_data = CustomTensorDataset(data=(x_train, y_train), transform=transform)\n",
    "val_data   = CustomTensorDataset(data=(x_val, y_val), transform=transform)\n",
    "test_data  = CustomTensorDataset(data=(x_test, y_test), transform=transform)\n",
    "\n",
    "# Build Dataloader\n",
    "train_loader = DataLoader(train_data, shuffle=True, **loader_kwargs)\n",
    "val_loader   = DataLoader(val_data, shuffle=True, **loader_kwargs)\n",
    "test_loader  = DataLoader(test_data, shuffle=False, **loader_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "     release  n_0002  n_0005  n_0012  n_0019  n_0034  n_0038  n_0047  n_0050  \\\n",
      "id                                                                             \n",
      "7905       c    0.05    0.29    0.15     0.2    0.19    0.18       1       1   \n",
      "\n",
      "      n_0052  ...  c_1326  c_1328  c_1330  c_1333  c_1335  c_1343  c_1348  \\\n",
      "id            ...                                                           \n",
      "7905       1  ...       g       b       a       b       w       b       b   \n",
      "\n",
      "      c_1361  c_1363  c_1372  \n",
      "id                            \n",
      "7905       h       b       a  \n",
      "\n",
      "[1 rows x 219 columns]\n"
     ]
    }
   ],
   "source": [
    "# for e, (imgs, labels) in enumerate(train_loader):\n",
    "#     print(e,imgs,labels)\n",
    "#     break\n",
    "for e, (imgs, labels) in enumerate(train_data):\n",
    "    print(len(imgs[0]))\n",
    "    break\n",
    "# print(y_train.head())\n",
    "print(x_train.head(1))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-13994e82b69c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# plt.imshow(x_imgs[0][0, :, :])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (x_imgs, labels) in enumerate(train_data):\n",
    "    #g+=1\n",
    "    print(x_imgs[0].shape)\n",
    "    plt.grid()\n",
    "    plt.imshow(x_imgs[0][0, :, :]) # plt.imshow(x_imgs[0][0, :, :])\n",
    "    plt.show()\n",
    "    g+=1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9000000000000001\n"
     ]
    }
   ],
   "source": [
    "# a =[[-0.,  0., -0.,  0.,  1.,  1., -0.,  0.,  0., -0., -1., -0., -0.,  1.],[ 0., -0.,  0., -0.,  1.,  0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.]] \n",
    "# b = [[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1]]\n",
    "from sklearn.metrics import f1_score\n",
    "a = [[0,0,0,1,1],[1,0,0,1,1]]\n",
    "b = [[0,0,0,1,1],[1,1,0,1,1]]\n",
    "accuracy_score = []\n",
    "\n",
    "for tru,pred in zip (a, b):\n",
    "    accuracy_score.append(f1_score(tru,pred,average='micro'))\n",
    "\n",
    "print(np.mean(accuracy_score))\n",
    "# f1(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    i = set(y_true).intersection(y_pred)\n",
    "    len1 = len(y_pred)\n",
    "    if len1 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(i) / len1\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    i = set(y_true).intersection(y_pred)\n",
    "    return len(i) / len(y_true)\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    if p + r == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * (p * r) / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomTensorDataset' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d7f6b1b209fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_train_RE.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_train_RE.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomTensorDataset' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# train_data.to_csv(\"X_train_RE.csv\")\n",
    "# train_labels.to_csv(\"y_train_RE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "tensor([[-0.0750]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0750]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 64])\n",
      "tensor([[0.0171]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.features1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 12, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.features2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 12, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(12*6*6, 64)\n",
    "        self.fc2 = nn.Linear(12*6*6, 64)\n",
    "        \n",
    "        self.my1 = nn.Linear(128,1)\n",
    "        self.my2 = nn.Linear(128,1)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x1, x2, classnr=0):\n",
    "        x1 = self.features1(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x1 = F.relu(self.fc1(x1))\n",
    "        print(x1.shape)\n",
    "        \n",
    "        x2 = self.features2(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x2 = F.relu(self.fc2(x2))\n",
    "\n",
    "        # Concatenate in dim1 (feature dimension)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        \n",
    "        if classnr == 0:\n",
    "            return self.my1(x)\n",
    "        elif classnr == 1:\n",
    "            return self.my2(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "x1 = torch.randn(1, 3, 24, 24)\n",
    "x2 = torch.randn(1, 1, 24, 24)\n",
    "output = model(x1, x2, 0)\n",
    "print(output)\n",
    "output2 = model(x1, x2, 1)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[...,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
